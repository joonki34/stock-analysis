{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Google API key from the environment variables\n",
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# Create a Google Generative AI instance with the specified model and API key\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\", google_api_key=api_key, cache=True)\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a professional Wall Street analyst. I want you to predict if an Elon Musk's tweet would have positive effect on the stock price of Tesla Inc (TSLA). Here's one of the Elon Musk's tweet below:\n",
    "---\n",
    "{tweet}\n",
    "---\n",
    "\n",
    "The report should have the following format:\n",
    "---\n",
    "Prediction: Positive / Negative\n",
    "Reason:\n",
    "---\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Create a language chain with the LLM and the parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "print(chain.invoke({\"tweet\": \"Next I'm buying Coca-Cola to put the cocaine back in.\"}))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
